{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import re\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "    for l in gzip.open(fname):\n",
    "        yield eval(l)\n",
    "\n",
    "data = list(parseData(\"C:/Users/iisab/OneDrive/Documents/School/Fall2023/CSE158/Assignment2/australian_user_reviews.json.gz\"))\n",
    "\n",
    "dm = [[0,0],[0,0]]\n",
    "\n",
    "users = set()\n",
    "games = set()\n",
    "\n",
    "nodate = 0\n",
    "\n",
    "reviews = []\n",
    "\n",
    "for user in data:\n",
    "    if user[\"user_id\"] in users:\n",
    "        #print(f\"ducplicate user skipped: {user['user_id']}\")\n",
    "        pass\n",
    "    else:\n",
    "        users.add(user[\"user_id\"])\n",
    "        for review in user[\"reviews\"]:\n",
    "            games.add(review[\"item_id\"])\n",
    "            funny = review[\"funny\"]\n",
    "            hasfunny = int(funny != \"\")\n",
    "            if funny == \"\":\n",
    "                review[\"funny\"] = 0\n",
    "            else:\n",
    "                review[\"funny\"] = int(re.findall(\"\\d+\", funny)[0])\n",
    "                \n",
    "            helpful = review[\"helpful\"]\n",
    "            hashelpful = int(helpful != \"No ratings yet\")\n",
    "            if helpful == \"No ratings yet\":\n",
    "                review[\"helpful_n\"] = 0\n",
    "                review[\"helpful_total\"] = 0\n",
    "                review[\"helpful\"] = 0\n",
    "            else:\n",
    "                nums = re.findall(\"\\d+\", helpful.replace(\",\", \"\"))\n",
    "                helpfulness = float(nums[0]) / float(nums[1])\n",
    "                review[\"helpful\"] = float(nums[0]) / float(nums[1])\n",
    "                review[\"helpful_n\"] = float(nums[0])\n",
    "                review[\"helpful_total\"] = float(nums[1])\n",
    "            \n",
    "            dm[hasfunny][hashelpful] += 1\n",
    "\n",
    "            try:\n",
    "                post_datetime = datetime.strptime(review[\"posted\"],'Posted %B %d, %Y.')\n",
    "                review[\"posted\"] = post_datetime\n",
    "            except:\n",
    "                nodate += 1\n",
    "\n",
    "            review[\"user_id\"] = user[\"user_id\"]\n",
    "            review[\"user_url\"] = user[\"user_url\"]\n",
    "            reviews.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97248"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "stemmer = PorterStemmer()\n",
    "for review in reviews:\n",
    "\tr = ''.join([c for c in review['review'].lower() if not c in punctuation])\n",
    "\tfor w in r.split():\n",
    "\t\tw = stemmer.stem(w)\n",
    "\t\twordCount[w] += 1\n",
    "\t\t\n",
    "len(wordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'game',\n",
       " 'and',\n",
       " 'a',\n",
       " 'to',\n",
       " 'it',\n",
       " 'is',\n",
       " 'i',\n",
       " 'of',\n",
       " 'you',\n",
       " 'thi',\n",
       " 'in',\n",
       " 'for',\n",
       " 'that',\n",
       " 'play',\n",
       " 'with',\n",
       " 'but',\n",
       " 'have',\n",
       " 'on',\n",
       " 'be']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT GONNA USE DIDN'T PERFORM WELL AT ALL\n",
    "# wordCount = defaultdict(int)\n",
    "# punctuation = set(string.punctuation)\n",
    "# def feature(datum):\n",
    "#     feat = [0]*len(words)\n",
    "#     r = ''.join([c for c in datum['review'].lower() if not c in punctuation])\n",
    "#     ws = r.split()\n",
    "#     ws2 = [' '.join(x) for x in list(zip(ws[:-1],ws[1:]))]\n",
    "#     ws3 = [' '.join(x) for x in list(zip(ws[:-2],ws[1:-1],ws[2:]))]\n",
    "#     ws4 = [' '.join(x) for x in list(zip(ws[:-3],ws[1:-2],ws[2:-1],ws[3:]))]\n",
    "#     ws5 = [' '.join(x) for x in list(zip(ws[:-4],ws[1:-3],ws[2:-2],ws[3:-1],ws[4:]))]\n",
    "#     for w in ws + ws2 + ws3 + ws4 + ws5:\n",
    "#         if w in words:\n",
    "#             feat[wordId[w]] += 1\n",
    "#     feat.append(1) #offset\n",
    "#     return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import math\n",
    "df = defaultdict(int)\n",
    "\n",
    "train, test = train_test_split(reviews, test_size=0.25, random_state=0)\n",
    "\n",
    "for d in train:\n",
    "    r = ''.join([c for c in d['review'].lower() if not c in punctuation])\n",
    "    # for each word in the text\n",
    "    for w in set(r.split()):\n",
    "        # if this particular word is one we are looking for add 1 to document frequency\n",
    "        if w in words:\n",
    "            df[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['review'].lower() if not c in punctuation])\n",
    "    for word in r.split():\n",
    "        if word in words:\n",
    "            feat[wordId[word]] += 1\n",
    "    # offset\n",
    "    \n",
    "    return [1] + [feat[wordId[w]] * math.log10(len(train) / df[w]) for w in words if df[w] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy: 0.3884819442067431\n",
      "baseline error rate: 0.6115180557932569\n"
     ]
    }
   ],
   "source": [
    "threshold = 1\n",
    "\n",
    "baseline_accuracy = np.sum([0 if review[\"helpful_n\"] < threshold else 1 for review in reviews]) / len(reviews) # accuracy\n",
    "baseline_error_rate = 1 - np.sum([0 if review[\"helpful_n\"] < threshold else 1 for review in reviews]) / len(reviews) # error rate\n",
    "print(\"baseline accuracy: \" + str(baseline_accuracy) + \"\\nbaseline error rate: \" + str(baseline_error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [feature(review) for review in train]\n",
    "#Y_funny_train = [1 if review[\"funny\"] > 25 else 0 for review in train]\n",
    "Y_helpful_train = [1 if review[\"helpful_n\"] > 1 else 0 for review in train] # try with higher threshold 5, 10\n",
    "\n",
    "X_test = [feature(review) for review in test]\n",
    "#Y_funny_test = [1 if review[\"funny\"] > 25 else 0 for review in test]\n",
    "Y_helpful_test = [1 if review[\"helpful_n\"] > 1 else 0 for review in test] # try with higher threshold 5, 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "#mod_funny = linear_model.LogisticRegression(C=1, max_iter=1000)\n",
    "mod_helpful = linear_model.LogisticRegression(C=1, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod_funny.fit(X_train, Y_funny_train)\n",
    "mod_helpful.fit(X_train, Y_helpful_train)\n",
    "\n",
    "#predictions_funny = mod_funny.predict(X_test)\n",
    "predictions_helpful = mod_helpful.predict(X_test)\n",
    "\n",
    "#correct_funny = predictions_funny == Y_funny_test\n",
    "correct_helpful = predictions_helpful == Y_helpful_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_helpful: 0.7983296823658269\n",
      "error_rate: 0.2016703176341731\n"
     ]
    }
   ],
   "source": [
    "#accuracy_funny = sum(correct_funny) / len(correct_funny)\n",
    "accuracy_helpful = sum(correct_helpful) / len(correct_helpful)\n",
    "#print(\"accuracy_funny: \" + str(accuracy_funny) + \", accuracy_helpful: \" + str(accuracy_helpful))\n",
    "error_rate_helpful = 1 - accuracy_helpful\n",
    "print(\"accuracy_helpful: \" + str(accuracy_helpful) + \"\\nerror_rate: \" + str(error_rate_helpful))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
